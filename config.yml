load:
  type: constant
  stages:
  - rate: 1
    duration: 30
api: 
  type: chat
  streaming: true
server:
  type: vllm
  model_name: meta-llama/Meta-Llama-3-8B
  base_url: http://localhost:8000
  ignore_eos: true
tokenizer:
  pretrained_model_name_or_path: meta-llama/Meta-Llama-3-8B
data:
  type: shareGPT
report:
  request_lifecycle:
    summary: true
    per_stage: true
    per_request: false
  prometheus:
    summary: true
    per_stage: false